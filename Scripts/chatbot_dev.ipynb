{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd7cd253",
   "metadata": {},
   "source": [
    "# Chatbot Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebf9914",
   "metadata": {},
   "source": [
    "## Source Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c902da",
   "metadata": {},
   "source": [
    "Before developing the chatbot, the sources it will retrieve information from need to be formatted properly in a readable format. Code files (ipynb format) and the latest report (Milestone 2 as pdf) will be converted to txt files. These will be the main sources of information for the chatbot. \"data_access_info.txt\" and the GitHub README will also be included. The material will be stored in a folder called \"Chatbot_Knowledge\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1874f5",
   "metadata": {},
   "source": [
    "We will first convert ipynb notebooks to txt files ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7486d0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection.ipynb content successfully written to '../Chatbot_Knowledge/data_collection.txt'\n",
      "data_processing.ipynb content successfully written to '../Chatbot_Knowledge/data_processing.txt'\n",
      "training.ipynb content successfully written to '../Chatbot_Knowledge/training.txt'\n",
      "testing.ipynb content successfully written to '../Chatbot_Knowledge/testing.txt'\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "import os\n",
    "\n",
    "def convert_ipynb_to_txt(ipynb_path, txt_path):\n",
    "\n",
    "    \"\"\" Converts ipynb to txt file \"\"\"\n",
    "\n",
    "    # Load ipynb file\n",
    "    with open(ipynb_path, 'r', encoding='utf-8') as notebook_file:\n",
    "        notebook_content = nbformat.read(notebook_file, as_version=4)\n",
    "    \n",
    "    # Write content to txt file\n",
    "    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "\n",
    "        # Write name of original file\n",
    "        txt_file.write(f'\\n\\nThis file is the content of \"{ipynb_path}\"\\n\\n')\n",
    "\n",
    "        for cell in notebook_content['cells']:\n",
    "            # Handle code cells\n",
    "            if cell['cell_type'] == 'code':\n",
    "                txt_file.write('Code Cell:\\n')\n",
    "                txt_file.write('```python\\n')\n",
    "                txt_file.write(''.join(cell['source']))\n",
    "                txt_file.write('\\n```\\n\\n')\n",
    "            \n",
    "            # Handle markdown cells\n",
    "            elif cell['cell_type'] == 'markdown':\n",
    "                txt_file.write('Markdown Cell:\\n')\n",
    "                txt_file.write('## Markdown Content:\\n')\n",
    "                txt_file.write(''.join(cell['source']))\n",
    "                txt_file.write('\\n\\n')\n",
    "        \n",
    "        print(f\"{ipynb_path} content successfully written to '{txt_path}'\")\n",
    "\n",
    "# Convert ipynb notebooks to txt\n",
    "storage_folder = '../Chatbot_Knowledge/'\n",
    "\n",
    "if not os.path.exists(storage_folder):\n",
    "    os.mkdir(storage_folder)\n",
    "\n",
    "notebooks = ['data_collection.ipynb', 'data_processing.ipynb', 'training.ipynb', 'testing.ipynb']\n",
    "\n",
    "for ipynb_path in notebooks:\n",
    "    root_name = ipynb_path.split('.')[0]\n",
    "    txt_path = root_name + '.txt'\n",
    "    convert_ipynb_to_txt(ipynb_path, storage_folder + txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ac062",
   "metadata": {},
   "source": [
    "Now we will convert the latest report (pdf) to a txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c860cbbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Report/Milestone2.pdf content successfully written to ../Chatbot_Knowledge/Milestone2.txt\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "latest_report_path = '../Report/Milestone2.pdf'\n",
    "\n",
    "with pdfplumber.open(latest_report_path) as pdf:\n",
    "\n",
    "    text = ''\n",
    "\n",
    "    # Extract text from all pages\n",
    "    for i, page in enumerate(pdf.pages):\n",
    "\n",
    "        text += page.extract_text()\n",
    "\n",
    "    # Write to txt\n",
    "    root_name = latest_report_path.split('/')[-1].split('.pdf')[0]\n",
    "    txt_path = storage_folder + root_name + '.txt'\n",
    "\n",
    "    with open(txt_path, 'w') as txt_file:\n",
    "        txt_file.write(f'\\n\\nThis file is the content of \"{latest_report_path}\"\\n\\n')\n",
    "        txt_file.write(text)\n",
    "\n",
    "    print(f'{latest_report_path} content successfully written to {txt_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40159423",
   "metadata": {},
   "source": [
    "We will show the files currently in the knowledge base. Some were generated with the previous code. A few others such as \"data_access_info.txt\" and \"requirements.txt\" were dragged into the folder. We can also get an estimate of the number of tokens in the txt files by using the T5 tokenizer. T5 is a free and open source model on HuggingFace that can handle large inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97341cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in Knowledge Base\n",
      "---------------------------\n",
      "1. data_access_info.txt: 645 tokens\n",
      "2. data_collection.txt: 1316 tokens\n",
      "3. data_processing.txt: 9342 tokens\n",
      "4. Milestone2.txt: 8839 tokens\n",
      "5. README.txt: 812 tokens\n",
      "6. requirements.txt: 141 tokens\n",
      "7. testing.txt: 6769 tokens\n",
      "8. training.txt: 16367 tokens\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-t5/t5-large')\n",
    "\n",
    "# Show files in knowledge base and tokens\n",
    "print('Files in Knowledge Base')\n",
    "print('---------------------------')\n",
    "\n",
    "for i, source_name in enumerate(os.listdir(storage_folder)):\n",
    "    source_path = storage_folder + source_name\n",
    "\n",
    "    with open(source_path, 'r') as txt_file:\n",
    "        content = txt_file.read()\n",
    "        num_tokens = len(tokenizer(content)['input_ids'])\n",
    "        print(f'{i+1}. {source_name}: {num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c41e82",
   "metadata": {},
   "source": [
    "The content in all these files can then be combined into one txt file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cfb578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined knowledge base was successfully stored in \"../Chatbot_Knowledge/combined_knowledge.txt\" and is equivalent to about 44226 tokens\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Load all text\n",
    "storage_folder = '../Chatbot_Knowledge/'\n",
    "knowledge_base = ''\n",
    "\n",
    "for source_name in os.listdir(storage_folder):\n",
    "\n",
    "    source_path = storage_folder + source_name\n",
    "\n",
    "    with open(source_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        knowledge_base += content\n",
    "\n",
    "# Combine all knowledge into one file\n",
    "combined_path = storage_folder + 'combined_knowledge.txt'\n",
    "\n",
    "with open(combined_path, 'w') as file:\n",
    "    file.write(knowledge_base)\n",
    "\n",
    "# Show number of tokens\n",
    "num_tokens = len(tokenizer(knowledge_base)['input_ids'])\n",
    "print(f'Combined knowledge base was successfully stored in \"{combined_path}\" and is equivalent to about {num_tokens} tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32194d",
   "metadata": {},
   "source": [
    "## Using Open AI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6047a4d4",
   "metadata": {},
   "source": [
    "To use Open AI API to ask questions about the knowledge base, the content of the knowledge base needs to be loaded back in. The API can then be called to answer a question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862e6f42",
   "metadata": {},
   "source": [
    "A simple flask app will be used for the user interface. To access it, simply run *chatbot_app.py* in *Scripts*. It will provide you with a locally run website that you can visit to interact with the chatbot. You can change the script to use a different port if desired. Behind the scenes, it will call a Google Cloud function that contacts Open AI API and returns responses to the user's prompts. Google Cloud was used to protect the API key for Open AI so here is the code that is hosted there (API key not shown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b5c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions_framework\n",
    "from openai import OpenAI\n",
    "\n",
    "@functions_framework.http\n",
    "def ask_question(request):\n",
    "\n",
    "    \"\"\" User asks a question and chatbot's response is returned \"\"\"\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        try:\n",
    "            # Read request\n",
    "            data = request.get_json()\n",
    "            user_prompt = data.get('message', 'Sorry ... no message recognized.')\n",
    "            \n",
    "            # API key: DO NOT SHARE!!!\n",
    "            API_KEY = ''\n",
    "\n",
    "            # Load knowledge base\n",
    "            combined_path = 'combined_knowledge.txt'\n",
    "            knowledge_base = ''\n",
    "\n",
    "            with open(combined_path, 'r') as file:\n",
    "                knowledge_base = file.read()\n",
    "\n",
    "            # Contact API with key\n",
    "            client = OpenAI(\n",
    "            api_key=API_KEY\n",
    "            )\n",
    "\n",
    "            # Set up chatbot's expected behavior and feed it the knowledge base of the project\n",
    "            behavior_msg = \"Michael Calderin did a project using machine learning to classify transits from NASA's Kepler mission as true planets or not. The work is hosted on GitHub at https://github.com/michaelcalderin/cap5771sp25-project. Your job is to answer questions related to the project. The content in the code files, written report, etc. will be the following so use this material to answer questions and do not stray from this task:\"\n",
    "            system_content = f'{behavior_msg}\\n{knowledge_base}'\n",
    "\n",
    "            # Fetch the response\n",
    "            completion = client.chat.completions.create(\n",
    "                model='gpt-4.1-nano',\n",
    "                messages=[\n",
    "                {'role': 'system', 'content': system_content},\n",
    "                {'role': 'user', 'content': user_prompt}\n",
    "                ],\n",
    "                max_completion_tokens=300\n",
    "            )\n",
    "\n",
    "            response = completion.choices[0].message.content\n",
    "            return response\n",
    "        \n",
    "        except Exception as e:\n",
    "            return f'Error: {str(e)}'\n",
    "\n",
    "    return ''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
